{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karczel/01219114-2022f-w8-bag/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXfysQWAWIBn"
      },
      "outputs": [],
      "source": [
        "!pip install pycaret feature-engine imbalanced-learn folium mapclassify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyZdUYdPHDnI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "os.environ['USE_PYGEOS'] = '0'\n",
        "import geopandas as gpd\n",
        "import pickle\n",
        "\n",
        "import pycaret\n",
        "from pycaret.regression import *\n",
        "\n",
        "import sklearn\n",
        "from sklearn import set_config\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, mutual_info_regression, f_regression\n",
        "\n",
        "from imblearn.pipeline import Pipeline as imbPipeline\n",
        "\n",
        "import feature_engine\n",
        "from feature_engine.selection import DropFeatures, DropConstantFeatures, DropDuplicateFeatures, DropCorrelatedFeatures\n",
        "from feature_engine.imputation import MeanMedianImputer, RandomSampleImputer, CategoricalImputer\n",
        "from feature_engine.outliers import OutlierTrimmer\n",
        "from feature_engine.transformation import YeoJohnsonTransformer, LogCpTransformer\n",
        "from feature_engine.encoding import OneHotEncoder as Ohe\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "set_config(display='diagram')\n",
        "\n",
        "pd.options.display.max_rows = 999999\n",
        "pd.options.display.max_columns = 999999\n",
        "pd.set_option('display.float_format', lambda x: '%.03f' % x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRDepphtP9mj"
      },
      "outputs": [],
      "source": [
        "print(pd.__version__)\n",
        "print(gpd.__version__)\n",
        "print(pycaret.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9KL6f7eQAt7"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ng2zNSUQD5U"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUksUCg-Q_tk"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHI3GRPvrkn0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('raw_dataset_eng.xlsx')\n",
        "df.columns = [col.lower() for col in df.columns]\n",
        "print(df.shape)\n",
        "df[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeUS_i9Pw_Xr"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqblOnRBP4Rk"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWqcEM2gP4US"
      },
      "outputs": [],
      "source": [
        "df = df[df['date'] != 0].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akg_aAkmxIpD"
      },
      "outputs": [],
      "source": [
        "df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn_tQlJ-wBVm"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values(by='date').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-GqeqeAxTpR"
      },
      "outputs": [],
      "source": [
        "df[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgRyLssyxZh6"
      },
      "outputs": [],
      "source": [
        "df = df.drop(index=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR5DH9vsxixB"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-pRGAxRxv2r"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmLQXd_W2EGd"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM4vijMOxo7B"
      },
      "outputs": [],
      "source": [
        "del df['id'], df['date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLVEbuD_10mg"
      },
      "outputs": [],
      "source": [
        "df = df.rename(columns={'house_price': 'target'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFlw0n7fxHWc"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbSERlGgT4xG"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47fBC3MNT6I2"
      },
      "outputs": [],
      "source": [
        "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs='EPSG:4326')\n",
        "gdf = gdf.to_crs(epsg=24047)\n",
        "print(gdf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IChgALmQT8WG"
      },
      "outputs": [],
      "source": [
        "gdf.explore()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1WcGrE2T_Et"
      },
      "source": [
        "# Some clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f60QpFtIUBXF"
      },
      "outputs": [],
      "source": [
        "# Data cleansing - out-of-bound deletion\n",
        "\n",
        "boundary = gpd.read_file('Nonthaburi.shp')\n",
        "boundary = boundary.to_crs(gdf.crs.to_string())\n",
        "boundary = boundary[['geometry']]\n",
        "\n",
        "gdf = gpd.sjoin(gdf, boundary, how='left', predicate='within')\n",
        "gdf = gdf.dropna(subset=['index_right'])\n",
        "del gdf['index_right']\n",
        "print(gdf.shape)\n",
        "gdf[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaYKqbAo8STH"
      },
      "outputs": [],
      "source": [
        "# Remove some outliers\n",
        "\n",
        "def remove_outliers(df, field_name):\n",
        "    q25 = np.nanpercentile(df[field_name], 25)\n",
        "    q75 = np.nanpercentile(df[field_name], 75)\n",
        "    iqr = q75 - q25\n",
        "    upperbound = q75 + iqr * 1.5\n",
        "    lowerbound = q25 - iqr * 1.5\n",
        "\n",
        "    df = df[(df[field_name] <= upperbound) & (df[field_name] >= lowerbound)]\n",
        "\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "gdf = remove_outliers(gdf, 'target')\n",
        "gdf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jibzxFoeKwE"
      },
      "outputs": [],
      "source": [
        "gdf.drop(columns=['geometry']).to_csv('initial_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGcCcUQzdefp"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/initial_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM3NtiuMUBgN"
      },
      "outputs": [],
      "source": [
        "m = gdf.explore(column='target', cmap='Reds')\n",
        "boundary.explore(m=m, style_kwds={'stroke': True, 'color': 'black', 'fill': False, 'fillOpacity': 0})\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUCQThpvQ72T"
      },
      "source": [
        "# Find Promising Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeUUeTdGQ-3D"
      },
      "outputs": [],
      "source": [
        "s = setup(gdf.drop(columns=['geometry']), target='target', fold=2, session_id=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EWGG-g_RRzT"
      },
      "outputs": [],
      "source": [
        "best = compare_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLYYSRG0YlrY"
      },
      "outputs": [],
      "source": [
        "rf = create_model('rf')\n",
        "rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hphLmoQjTIlh"
      },
      "outputs": [],
      "source": [
        "plot_model(rf, plot='residuals')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2mGmdsyXizE"
      },
      "outputs": [],
      "source": [
        "plot_model(rf, plot='error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7893ripyj_L"
      },
      "source": [
        "# Pipeline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVJ7rtc8yubx"
      },
      "source": [
        "## Custom Transformer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuu-yhLTyl6K"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class QualityTransformer(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    self.mapper = {'very bad': 1, 'bad': 2, 'fair': 3, 'good': 4, 'very good': 5}\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    _X = X.copy()\n",
        "    _X['quality'] = _X['quality'].map(self.mapper)\n",
        "\n",
        "    return _X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39_K1vPLyy6x"
      },
      "source": [
        "## Train-Test-Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHA1EvtXymUb"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN2QN-JjymWo"
      },
      "outputs": [],
      "source": [
        "X_train[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcvkO3aVzdm8"
      },
      "source": [
        "## Pipeline - Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV1j55lqymZH"
      },
      "outputs": [],
      "source": [
        "num_cols = df.drop(columns=['target']).select_dtypes(include=['int', 'float']).columns.tolist()\n",
        "cat_cols = df.drop(columns=['target']).select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(num_cols)\n",
        "print(cat_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdh14eddziSc"
      },
      "outputs": [],
      "source": [
        "num_pipeline = Pipeline(steps=[\n",
        "                                ('impute', SimpleImputer(strategy='mean')),\n",
        "                                ('robust_scale', RobustScaler())\n",
        "                            ])\n",
        "cat_pipeline = Pipeline(steps=[\n",
        "                                ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "                                ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "                            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsvS_xz0ziU2"
      },
      "outputs": [],
      "source": [
        "col_trans = ColumnTransformer(transformers=[\n",
        "                                            ('num_pipeline', num_pipeline, num_cols),\n",
        "                                            ('cat_pipeline', cat_pipeline, cat_cols)\n",
        "                                            ],\n",
        "                                            remainder='drop',\n",
        "                                            n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdGKTHXOziXd"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI_ujOeEziZ9"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(steps=[\n",
        "                            ('quality_trans', QualityTransformer()),\n",
        "                            ('col_trans', col_trans),\n",
        "                            ('features_selector', SelectPercentile(mutual_info_regression, percentile=25)),\n",
        "                            ('model', rf)\n",
        "                        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5J_TBLVzicW"
      },
      "outputs": [],
      "source": [
        "display(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xkxDAaOzifB"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "score = pipeline.score(X_test, y_test)\n",
        "print(f'Model R2: {score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmrssjlvzrpM"
      },
      "outputs": [],
      "source": [
        "# grid_params = {\n",
        "#     'model__n_estimators': [300, 750],\n",
        "#     'model__max_depth': [7, 9]\n",
        "# }\n",
        "\n",
        "# pipeline = GridSearchCV(pipeline, grid_params, cv=2, scoring='r2')\n",
        "# pipeline.fit(X_train, y_train)\n",
        "\n",
        "# print('Best Score of train set: ' + str(pipeline.best_score_))\n",
        "# print('Best parameter set: ' + str(pipeline.best_params_))\n",
        "# print('Test Score: ' + str(pipeline.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MASa48hb0lt1"
      },
      "source": [
        "## Pipeline - Feature-Engine Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpocS9Xl0rJG"
      },
      "outputs": [],
      "source": [
        "gbt = GradientBoostingRegressor(n_estimators=100, random_state=0)\n",
        "knn = KNeighborsRegressor(n_neighbors=7, n_jobs=-1)\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=5, n_jobs=-1, random_state=0)\n",
        "\n",
        "gbt_knn_rf = VotingRegressor(estimators=[('gbt', gbt), ('knn', knn), ('rf', rf)], weights=[5, 2, 3], n_jobs=-1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nvVh5q2T_AA"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s9cdCNU0s8P"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    # Step 1: Drop features containing only 1 value\n",
        "    ('drop_constant_values', DropConstantFeatures(tol=1, missing_values='ignore')),\n",
        "\n",
        "    # Step 2: Drop duplicated features\n",
        "    ('drop_duplicates', DropDuplicateFeatures()),\n",
        "\n",
        "    # Step 3: Drop correlated features\n",
        "    ('drop_correlated', DropCorrelatedFeatures(method='pearson', threshold=0.7)),\n",
        "\n",
        "    # Step 4: Some transformations\n",
        "    ('quality_trans', QualityTransformer()),\n",
        "\n",
        "    # Step 5: Imputations\n",
        "    ('impute_num', MeanMedianImputer(imputation_method='mean')),\n",
        "    ('impute_cat', CategoricalImputer(imputation_method='frequent')),\n",
        "\n",
        "    # # Step 6: Log transformations\n",
        "    ('log', LogCpTransformer()),\n",
        "\n",
        "    # Step 7: One hot encoding\n",
        "    ('ohe', Ohe()),\n",
        "\n",
        "    # Step 8: Regressor\n",
        "    ('ensemble', rf)\n",
        "])\n",
        "\n",
        "display(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7MNfIH50s-2"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "score = pipeline.score(X_test, y_test)\n",
        "print(f'Model R2: {score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibXHobFT02DE"
      },
      "outputs": [],
      "source": [
        "pipeline[:-1].fit_transform(X_train)[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwTMkx5T02F6"
      },
      "outputs": [],
      "source": [
        "pipeline[:-1].fit_transform(X_train).columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHaUJz5f02H0"
      },
      "outputs": [],
      "source": [
        "importances = pipeline.steps[-1][1].feature_importances_\n",
        "feature_imp = pd.DataFrame(importances,\n",
        "                           columns=['importance_score'],\n",
        "                           index=pipeline[:-1].fit_transform(X_train).columns.tolist()).reset_index(drop=False).rename(columns={'index': 'features'}).sort_values(by='importance_score', ascending=False).reset_index(drop=True)\n",
        "feature_imp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqM6W53_1D9h"
      },
      "source": [
        "## Pipeline - Feature-Engine + Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lkJmpxqVHSH"
      },
      "outputs": [],
      "source": [
        "from feature_engine.wrappers import SklearnTransformerWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV5WIjtb1o1w"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    # Step 1: Drop features containing only 1 value\n",
        "    ('drop_constant_values', DropConstantFeatures(tol=1, missing_values='ignore')),\n",
        "\n",
        "    # Step 2: Drop duplicated features\n",
        "    ('drop_duplicates', DropDuplicateFeatures()),\n",
        "\n",
        "    # Step 3: Drop correlated features\n",
        "    ('drop_correlated', DropCorrelatedFeatures(method='pearson', threshold=0.7)),\n",
        "\n",
        "    # Step 4: Some transformations\n",
        "    ('quality_trans', QualityTransformer()),\n",
        "\n",
        "    # Step 5: Imputations\n",
        "    ('impute_num', MeanMedianImputer(imputation_method='mean')),\n",
        "    ('impute_cat', CategoricalImputer(imputation_method='frequent')),\n",
        "\n",
        "    # Step 6: Robust scaling\n",
        "    ('robust_scale', SklearnTransformerWrapper(RobustScaler())),\n",
        "\n",
        "    # Step 7: One hot encoding\n",
        "    ('ohe', Ohe()),\n",
        "\n",
        "    # Step 8: Voting regressor\n",
        "    ('ensemble', gbt_knn_rf)\n",
        "])\n",
        "\n",
        "display(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpn5kZox1o4g"
      },
      "outputs": [],
      "source": [
        "pipeline[:-1].fit_transform(X_train)[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUTUxkWJ1o7V"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "score = pipeline.score(X_test, y_test)\n",
        "print(f'Model R2: {score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntB9DPlb2SYs"
      },
      "source": [
        "## Pipeline - Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7W7ROE81pAh"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    # Step 1: Drop features containing only 1 value\n",
        "    ('drop_constant_values', DropConstantFeatures(tol=1, missing_values='ignore')),\n",
        "\n",
        "    # Step 2: Drop duplicated features\n",
        "    ('drop_duplicates', DropDuplicateFeatures()),\n",
        "\n",
        "    # Step 3: Drop correlated features\n",
        "    ('drop_correlated', DropCorrelatedFeatures(method='pearson', threshold=0.7)),\n",
        "\n",
        "    # Step 4: Some transformations\n",
        "    ('quality_trans', QualityTransformer()),\n",
        "\n",
        "    # Step 5: Imputations\n",
        "    ('impute_num', MeanMedianImputer(imputation_method='mean')),\n",
        "    ('impute_cat', RandomSampleImputer(random_state=0)),\n",
        "\n",
        "    # Step 6: Robust scaling\n",
        "    ('robust_scale', SklearnTransformerWrapper(RobustScaler())),\n",
        "\n",
        "    # Step 7: One hot encoding\n",
        "    ('ohe', Ohe()),\n",
        "\n",
        "    # Step 8: Feature selection\n",
        "    ('feature_selector', SelectPercentile(mutual_info_regression, percentile=50)),\n",
        "\n",
        "    # Step 9: Voting regressor\n",
        "    ('ensemble', gbt_knn_rf)\n",
        "])\n",
        "\n",
        "display(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9rHvAdR1pC3"
      },
      "outputs": [],
      "source": [
        "pipeline[:-1].fit_transform(X_train, y_train)[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3KEHNeI2dLr"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "score = pipeline.score(X_test, y_test)\n",
        "print(f'Model R2: {score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvfUbMGj2gBC"
      },
      "source": [
        "## Pipeline - imbPipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8i9157M2lFo"
      },
      "outputs": [],
      "source": [
        "pipeline = imbPipeline([\n",
        "    # Step 1: Drop features containing only 1 value\n",
        "    ('drop_constant_values', DropConstantFeatures(tol=1, missing_values='ignore')),\n",
        "\n",
        "    # Step 2: Drop duplicated features\n",
        "    ('drop_duplicates', DropDuplicateFeatures()),\n",
        "\n",
        "    # Step 3: Drop correlated features\n",
        "    ('drop_correlated', DropCorrelatedFeatures(method='pearson', threshold=0.7)),\n",
        "\n",
        "    # Step 4: Some transformations\n",
        "    ('quality_trans', QualityTransformer()),\n",
        "\n",
        "    # Step 5: Imputations\n",
        "    ('impute_num', MeanMedianImputer(imputation_method='mean')),\n",
        "    ('impute_cat', RandomSampleImputer(random_state=0)),\n",
        "\n",
        "    # Step 6: Robust scaling\n",
        "    ('robust_scale', SklearnTransformerWrapper(RobustScaler())),\n",
        "\n",
        "    # Step 7: One hot encoding\n",
        "    ('ohe', Ohe()),\n",
        "\n",
        "    # Step 8: Feature selection\n",
        "    ('feature_selector', SelectPercentile(mutual_info_regression, percentile=50)),\n",
        "\n",
        "    # Step 9: Voting regressor\n",
        "    ('ensemble', gbt_knn_rf)\n",
        "])\n",
        "\n",
        "display(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rum_xKUx2xRC"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "score = pipeline.score(X_test, y_test)\n",
        "print(f'Model R2: {score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj0TYR9821JR"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9HCZ82y2xTt"
      },
      "outputs": [],
      "source": [
        "pipeline.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2OsPzW12xVx"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'ensemble__gbt__n_estimators': [300, 500],\n",
        "    'ensemble__knn__n_neighbors': [7, 9],\n",
        "    'ensemble__rf__max_depth': [5, 7],\n",
        "    'ensemble__rf__n_estimators': [300, 500],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGu2pHIY2xYT"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "grid = RandomizedSearchCV(pipeline, params, scoring='r2', verbose=2, cv=2)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print('Best Score of train set: ' + str(grid.best_score_))\n",
        "print('Best parameter set: ' + str(grid.best_params_))\n",
        "print('Test Score: ' + str(grid.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07vrRABh3B6j"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-io83-4i3Co3"
      },
      "outputs": [],
      "source": [
        "X_test[X_test['direction'].notna()][:1].to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGgHMH1r3FjW"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train).predict(X_test[X_test['direction'].notna()][:1])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkOEUTwh3Hty"
      },
      "source": [
        "## Save Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G7qI4sy3KS3"
      },
      "outputs": [],
      "source": [
        "# import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdMSl8mB3Izf"
      },
      "outputs": [],
      "source": [
        "# pickle.dump(pipeline1, open('final_model.pkl'), 'wb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}